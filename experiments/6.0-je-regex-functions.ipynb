{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Experimentation_\n",
    "\n",
    "**TL:DR** --> Experiment with regex and `re` library. Hoping to build a multitude of functions that we can utilize to narrow down the observations that contain misinformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n",
      "/opt/conda/envs/fastai/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# import libraries\n",
    "import fundamentals\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Load Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings of file paths and file name for data\n",
    "origpath = \"/notebooks/CovidDisinfo-Detect/experiments\"\n",
    "datapath = \"/notebooks/CovidDisinfo-Detect/data/interim\"\n",
    "filename = \"covid19_20200324.pkl\"\n",
    "\n",
    "# load data into pandas dataframe\n",
    "df = fundamentals.load_data(origpath, datapath, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Regex & `re`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for newline characters\n",
    "def newline_search(text):\n",
    "    \"\"\"\n",
    "    Searches for newline characters in \n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"\\n+\", re.I)\n",
    "    if regex.findall(text) == []:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def newline_sub(text):\n",
    "    \"\"\"\n",
    "    Removes newline characters from text.\n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"\\n+\", re.I)\n",
    "    if regex.findall(text) == []:\n",
    "        return text\n",
    "    else:\n",
    "        return regex.sub(r\" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96c8b19493c4cae99892557624db496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1927244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new column without the newline characters\n",
    "df[\"clean_tweet\"] = df[\"tweet\"].progress_apply(newline_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1927244\n",
       "Name: clean_tweet, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to make sure our cleaning worked\n",
    "df[\"clean_tweet\"].apply(newline_search).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _`china_search`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that searches for China or Chinese \n",
    "def china_search(text):\n",
    "    \"\"\"\n",
    "    Searches for a given term within a text.\n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"china|chinese\", re.I)\n",
    "    if regex.findall(text) == []:\n",
    "        return \"N/a\"\n",
    "    elif regex.findall(text) != []:\n",
    "        return \",\".join(regex.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:59+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:58+00:00    N/a\n",
       "2020-03-23 06:59:57+00:00    N/a\n",
       "2020-03-23 06:59:57+00:00    N/a\n",
       "2020-03-23 06:59:57+00:00    N/a\n",
       "2020-03-23 06:59:57+00:00    N/a\n",
       "2020-03-23 06:59:57+00:00    N/a\n",
       "2020-03-23 06:59:57+00:00    N/a\n",
       "Name: clean_tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_tweet\"][:20].apply(china_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47abe1ee75004fa4b1aeec3cb430ea6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1927244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"chinese_search\"] = df[\"clean_tweet\"].progress_apply(lambda x: china_search(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "China                      29847\n",
       "Chinese                    15691\n",
       "China,China                 4291\n",
       "china                       3182\n",
       "China,china                 3118\n",
       "Chinese,Chinese             1635\n",
       "Chinese,China               1611\n",
       "China,Chinese               1575\n",
       "chinese                     1236\n",
       "China,China,China            857\n",
       "Chinese,chinese              707\n",
       "CHINA                        622\n",
       "CHINESE                      392\n",
       "China,China,china            293\n",
       "Chinese,China,China          289\n",
       "China,Chinese,China          264\n",
       "Chinese,china                256\n",
       "China,China,Chinese          255\n",
       "Chinese,Chinese,Chinese      236\n",
       "china,china                  228\n",
       "China,Chinese,Chinese        226\n",
       "Chinese,China,Chinese        219\n",
       "china,China                  186\n",
       "China,China,China,China      167\n",
       "Chinese,Chinese,China        154\n",
       "China,china,china            141\n",
       "China,chinese                132\n",
       "china,chinese                 96\n",
       "china,china,Chinese           95\n",
       "Name: chinese_search, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"chinese_search\"].value_counts()[1:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _`usa_search`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that searches for US-related terms\n",
    "def usa_search(text):\n",
    "    \"\"\"\n",
    "    Searches for US-related terms in given text\n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"usa|united states|america|american\", re.I)\n",
    "    if regex.findall(text) == []:\n",
    "        return \"N/a\"\n",
    "    elif regex.findall(text) != []:\n",
    "        return \",\".join(regex.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323bed7521f1408e8bf2e1ee3d738244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1927244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"usa_search\"] = df[\"clean_tweet\"].progress_apply(lambda x: usa_search(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "America                        34912\n",
       "usa                            16176\n",
       "USA                            12145\n",
       "United States                   3520\n",
       "america                         2938\n",
       "America,America                 2567\n",
       "America,america                 1922\n",
       "usa,usa                         1502\n",
       "USA,USA                         1029\n",
       "AMERICA                          771\n",
       "USA,usa                          580\n",
       "America,USA                      400\n",
       "usA                              387\n",
       "USA,America                      386\n",
       "United States,America            331\n",
       "America,usa                      284\n",
       "usa,America                      258\n",
       "usa,USA                          244\n",
       "Usa                              236\n",
       "America,America,America          231\n",
       "america,america                  159\n",
       "USA,USA,USA                      133\n",
       "uSa                              133\n",
       "United States,United States      115\n",
       "Name: usa_search, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"usa_search\"].value_counts()[1:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _`bioweapon_search`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bioweapon_search(text):\n",
    "    \"\"\"\n",
    "    Searches for 'bioweapon' or 'biological weapon' in text.\n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"(bio[\\s]?weapon[s]?)+|(biological weapon[s]?)\", re.I)\n",
    "    return \",\".join([word.group() for word in regex.finditer(text)])\n",
    "    #if regex.findall(text) == []:\n",
    "    #    return \"N/a\"\n",
    "    #elif regex.findall(text) != []:\n",
    "    #    return \",\".join(regex.findall(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a64cfa8bf245828c8b080f96f99260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1927244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"bioweapon_search\"] = df[\"clean_tweet\"].progress_apply(bioweapon_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                1926175\n",
       "bioweapon                           288\n",
       "biological weapon                   196\n",
       "bio weapon                          102\n",
       "BioWeapon                            63\n",
       "Bioweapon                            49\n",
       "bioweapon,bioweapon                  48\n",
       "bioweapons                           41\n",
       "biological weapons                   37\n",
       "Biological Weapon                    34\n",
       "bio weapons                          22\n",
       "Bioweapon,bioweapon                  18\n",
       "BioWeapons                           17\n",
       "Biological weapon                    15\n",
       "Biological Weapons                   15\n",
       "BIOWEAPON                            12\n",
       "Bio weapon                           12\n",
       "Bioweapons                           11\n",
       "Bio Weapon                           10\n",
       "BIOLOGICAL WEAPON                     7\n",
       "Biological weapons                    7\n",
       "BIO WEAPON                            6\n",
       "biological weapon,bioweapons          4\n",
       "bioweapons,bioweapons                 3\n",
       "Bio weapons                           3\n",
       "bio weapon,bio weapon                 3\n",
       "Name: bioweapon_search, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of observations with each value, representing the number of times bioweapon-related term appeared in text\n",
    "df[\"bioweapon_search\"].value_counts()[:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _`us_bioweapon`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"COVID-19 covid19 is usa  a american america bioweapons bio weapon biological weapon\"\n",
    "text2 = \"What if the covid covid19 covid-19 coVID19 corona virus virus was an american-made bio weapon bioweapons?\"\n",
    "text3 = \"What if this is an american bioweapon?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_bioweapon(text):\n",
    "    \"\"\"\n",
    "    Searches for combination of US-related terms & bioweapon-related terms.\n",
    "    \"\"\"\n",
    "    re_text = r\"(american|america|united states|usa)+|(bio[\\s]?weapon[s]?)+|(biological weapon[s]?)\"\n",
    "    regex = re.compile(re_text, re.I)\n",
    "    return \",\".join([x.group() for x in regex.finditer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usa,american,america,bioweapons,bio weapon,biological weapon'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_bioweapon(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#df[\"clean_tweet\"][:1].str.extractall(r\"(covid[-\\s]?19)+|(covid)|(corona[\\s]?virus)\", re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _`qanon_search`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"Is Jordan Sather Jorden Sathar and QAnon qanon q anon right about Covid19?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that searches for instances of qanon and Jordan Sather (YouTouber linked to QAnon)\n",
    "def qanon_search(text):\n",
    "    \"\"\"\n",
    "    Searchs for terms 'qanon' & 'Jordan Sather' in given text\n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"jord[ae]n sath[ae]r|(q(\\s)?anon)+\", re.I)\n",
    "    return \",\".join([x.group() for x in regex.finditer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jordan Sather,Jorden Sathar,QAnon,qanon,q anon'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qanon_search(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78261ee25ef428c9132fddf0ec521e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1927244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create new column that applies qanon_search function to clean_tweet column\n",
    "df[\"qanon_search\"] = df[\"clean_tweet\"].progress_apply(qanon_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     1926230\n",
       "QAnon                    591\n",
       "Qanon                    166\n",
       "qanon                    118\n",
       "QANON                     45\n",
       "QAnon,QAnon               35\n",
       "QANON,QANON               16\n",
       "QAnon,QAnon,QAnon          7\n",
       "QAnon,qanon                5\n",
       "qanon,QAnon                3\n",
       "Qanon,QAnon                3\n",
       "Qanon,qanon                3\n",
       "QAnon,Qanon                3\n",
       "Q Anon                     2\n",
       "q anon                     2\n",
       "Qanon,Qanon                2\n",
       "QAnon,QAnon,qanon          1\n",
       "Qanon,QAnon,qanon          1\n",
       "QANON,QAnon                1\n",
       "Qanon,QANON                1\n",
       "Q ANON                     1\n",
       "Q anon                     1\n",
       "QAnon,QAnon,Qanon          1\n",
       "qAnon                      1\n",
       "qanon,qanon                1\n",
       "QAnon,QANON                1\n",
       "Name: qanon_search, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"qanon_search\"].value_counts()[:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _`boiled_ginger_search`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = \"Did you know that apparently boiled ginger ginger on an empty stomach can kill the coronavirus?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boiled_ginger_search(text):\n",
    "    \"\"\"\n",
    "    Searches for potential instances espousing fake \"cure\" of consuming boiled ginger on an empty stomach.\n",
    "    \"\"\"\n",
    "    regex = re.compile(r\"boiled|(ginger)+|empty|(stomach)+\", re.I)\n",
    "    return \",\".join([x.group() for x in regex.finditer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boiled,ginger,ginger,empty,stomach'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boiled_ginger_search(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbc35a23a264855af114d741526a508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1927244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"boiled_ginger_search\"] = df[\"clean_tweet\"].progress_apply(boiled_ginger_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   1922276\n",
       "empty                                                 3129\n",
       "Empty                                                  505\n",
       "stomach                                                431\n",
       "empty,empty                                            186\n",
       "ginger                                                 185\n",
       "Ginger                                                 100\n",
       "Empty,empty                                             92\n",
       "boiled                                                  67\n",
       "EMPTY                                                   44\n",
       "Stomach,stomach                                         38\n",
       "Stomach                                                 34\n",
       "empty,stomach                                           26\n",
       "stomach,stomach                                         16\n",
       "BOILED                                                  12\n",
       "Boiled                                                   9\n",
       "empty,Empty                                              8\n",
       "ginger,ginger                                            8\n",
       "Ginger,Ginger                                            8\n",
       "Ginger,ginger                                            7\n",
       "empty,empty,empty                                        6\n",
       "boiled,boiled                                            6\n",
       "GINGER                                                   4\n",
       "empty,EMPTY                                              4\n",
       "Empty,Empty,Empty                                        2\n",
       "Ginger,ginger,Ginger                                     2\n",
       "Empty,Empty                                              2\n",
       "Stomach,Stomach,stomach                                  2\n",
       "EMPTY,EMPTY                                              2\n",
       "empty,empty,empty,empty                                  2\n",
       "STOMACH                                                  2\n",
       "Ginger,ginger,ginger                                     2\n",
       "Empty,empty,empty                                        2\n",
       "stomach,stomach,stomach                                  2\n",
       "Ginger,ginger,ginger,ginger                              1\n",
       "Empty,empty,empty,empty,empty                            1\n",
       "Stomach,Stomach                                          1\n",
       "stomach,Stomach                                          1\n",
       "ginger,ginger,ginger,ginger                              1\n",
       "ginger,Ginger                                            1\n",
       "Empty,Empty,empty                                        1\n",
       "stomach,empty,empty,stomach                              1\n",
       "Empty,Stomach                                            1\n",
       "Ginger,Ginger,Ginger                                     1\n",
       "ginger,Ginger,Ginger                                     1\n",
       "ginger,boiled                                            1\n",
       "empty,stomach,empty                                      1\n",
       "boiled,ginger                                            1\n",
       "empty,empty,empty,Empty                                  1\n",
       "empty,empty,empty,empty,empty,empty,empty,empty          1\n",
       "boiled,Ginger,boiled                                     1\n",
       "Empty,stomach                                            1\n",
       "ginger,ginger,Ginger                                     1\n",
       "EMPTY,empty                                              1\n",
       "empty,empty,empty,empty,empty                            1\n",
       "stomach,ginger                                           1\n",
       "ginger,empty,stomach                                     1\n",
       "Name: boiled_ginger_search, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"boiled_ginger_search\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
